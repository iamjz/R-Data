{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## values\n",
    "#app_name <- \"INSERT_APP_NAME_HERE\"\n",
    "#key <- \"INSERT_KEY_HERE\"\n",
    "#secret <- \"INSERT_SECRET_KEY_HERE\"\n",
    "\n",
    "## create app\n",
    "#app <- httr::oauth_app(app_name, key, secret)\n",
    "\n",
    "## create token (must be interactive session)\n",
    "#token <- httr::oauth1.0_token(\n",
    "#    httr::oauth_endpoints(\"twitter\"),\n",
    "#    app, cache = FALSE\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Token>\n",
       "<oauth_endpoint>\n",
       " request:   https://api.twitter.com/oauth/request_token\n",
       " authorize: https://api.twitter.com/oauth/authenticate\n",
       " access:    https://api.twitter.com/oauth/access_token\n",
       "<oauth_app> data_sci_8001\n",
       "  key:    nImVTaVIeo6tYlKnwYgxPRquQ\n",
       "  secret: <hidden>\n",
       "<credentials> oauth_token, oauth_token_secret, user_id, screen_name, x_auth_expires\n",
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## read and print token\n",
    "(token <- readRDS(\"token.rds\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'C:\\Users\\Jacky Zhao\\Desktop\\repos\\R-Data\\token.rds'"
      ],
      "text/latex": [
       "'C:\\textbackslash{}Users\\textbackslash{}Jacky Zhao\\textbackslash{}Desktop\\textbackslash{}repos\\textbackslash{}R-Data\\textbackslash{}token.rds'"
      ],
      "text/markdown": [
       "'C:\\Users\\Jacky Zhao\\Desktop\\repos\\R-Data\\token.rds'"
      ],
      "text/plain": [
       "[1] \"C:\\\\Users\\\\Jacky Zhao\\\\Desktop\\\\repos\\\\R-Data\\\\token.rds\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## expand full path to token\n",
    "path_to_token <- normalizePath(\"token.rds\")\n",
    "\n",
    "path_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'TWITTER_PAT=C:\\Users\\Jacky Zhao\\Desktop\\repos\\R-Data\\token.rds'"
      ],
      "text/latex": [
       "'TWITTER\\_PAT=C:\\textbackslash{}Users\\textbackslash{}Jacky Zhao\\textbackslash{}Desktop\\textbackslash{}repos\\textbackslash{}R-Data\\textbackslash{}token.rds'"
      ],
      "text/markdown": [
       "'TWITTER_PAT=C:\\Users\\Jacky Zhao\\Desktop\\repos\\R-Data\\token.rds'"
      ],
      "text/plain": [
       "[1] \"TWITTER_PAT=C:\\\\Users\\\\Jacky Zhao\\\\Desktop\\\\repos\\\\R-Data\\\\token.rds\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## create env variable TWITTER_PAT (with path to saved token)\n",
    "envvar <- paste0(\"TWITTER_PAT=\", path_to_token)\n",
    "\n",
    "envvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save as .Renviron file (or append if the file already exists)\n",
    "cat(envvar, file = \"~/.Renviron\", fill = TRUE, append = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally the .Renviron file is processed on startup. However, to make sure the current R session registers the environment variable without having to restart the entire session, we can use the `readRenviron()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## refresh .Renviron variables\n",
    "(readRenviron(\"~/.Renviron\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'C:UsersJacky ZhaoDesktopreposR-Datatoken.rds'"
      ],
      "text/latex": [
       "'C:UsersJacky ZhaoDesktopreposR-Datatoken.rds'"
      ],
      "text/markdown": [
       "'C:UsersJacky ZhaoDesktopreposR-Datatoken.rds'"
      ],
      "text/plain": [
       "[1] \"C:UsersJacky ZhaoDesktopreposR-Datatoken.rds\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sys.getenv(\"TWITTER_PAT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can assume the path to our Twitter token is stored as an environment variable, we can easily write a function that locates and reads-in the token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Token>\n",
       "<oauth_endpoint>\n",
       " request:   https://api.twitter.com/oauth/request_token\n",
       " authorize: https://api.twitter.com/oauth/authenticate\n",
       " access:    https://api.twitter.com/oauth/access_token\n",
       "<oauth_app> data_sci_8001\n",
       "  key:    nImVTaVIeo6tYlKnwYgxPRquQ\n",
       "  secret: <hidden>\n",
       "<credentials> oauth_token, oauth_token_secret, user_id, screen_name, x_auth_expires\n",
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## function to load twitter token\n",
    "read_twittertoken <- function() {\n",
    "    readRDS(path_to_token)\n",
    "}\n",
    "\n",
    "## test out function\n",
    "read_twittertoken()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we keep running the above code, we'll keep adding new lines to our environment file. In addition to creating a mess in your .Renviron file, each successive line will override the previous value. In other words, you're doomed to make a mistake; and when you do, it will override the times that worked. \n",
    "\n",
    "So, to fix this problem, let's take the code we used to create and save the token as an environment variable and turn it into a single, useful function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_renv_token <- function(path_to_token, override = FALSE) {\n",
    "    ## check path\n",
    "    stopifnot(\n",
    "        is.character(path_to_token),\n",
    "        file.exists(path_to_token)\n",
    "    )\n",
    "    ## expand to full path\n",
    "    path_to_token <- normalizePath(path_to_token)\n",
    "\n",
    "    ## store path to .Renviron\n",
    "    renv <- normalizePath(\"~/.Renviron\")\n",
    "    \n",
    "    ## if override = false and there's already a TWITTER_PAT, stop\n",
    "    ## else override and there's already a TWITTER_PAT, then drop TWITTER_PAT and\n",
    "    ## save new .Renviron\n",
    "    if (!override && !identical(Sys.getenv(\"TWITTER_PAT\"), \"\")) {\n",
    "        stop(\"There's already a TWITTER_PAT. Use `override = TRUE` to replace.\",\n",
    "            call. = FALSE)\n",
    "    } else if (!identical(Sys.getenv(\"TWITTER_PAT\"), \"\") && \n",
    "               file.exists(renv)) {\n",
    "        con <- file(renv)\n",
    "        x <- readLines(con, warn = FALSE)\n",
    "        close(con)\n",
    "        x <- grep(\"^TWITTER_PAT\", x, invert = TRUE, value = TRUE)\n",
    "        writeLines(x, renv)\n",
    "    }\n",
    "    \n",
    "    ## create env variable TWITTER_PAT (with path to saved token)\n",
    "    envvar <- paste0(\"TWITTER_PAT=\", path_to_token)\n",
    "    \n",
    "    ## save as .Renviron file (or append if the file already exists)\n",
    "    cat(envvar, file = renv, fill = TRUE, append = TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_renv_token(\"token.rds\", TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Token>\n",
       "<oauth_endpoint>\n",
       " request:   https://api.twitter.com/oauth/request_token\n",
       " authorize: https://api.twitter.com/oauth/authenticate\n",
       " access:    https://api.twitter.com/oauth/access_token\n",
       "<oauth_app> data_sci_8001\n",
       "  key:    nImVTaVIeo6tYlKnwYgxPRquQ\n",
       "  secret: <hidden>\n",
       "<credentials> oauth_token, oauth_token_secret, user_id, screen_name, x_auth_expires\n",
       "---"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "read_twittertoken()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search API\n",
    "\n",
    "Now let's create a function that allows us to query [Twitter's standard search API](https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets). In the code below, I've included all the documented parameters (see note for explanation of the additional `tweet_mode` parameter), setting the optional parameters to `NULL` and making some judgment calls about other ones (e.g., `result_type` and `include_entitities`).\n",
    "\n",
    "*Note*: in order to return the full (non-truncated) text of a tweet, a [recent change by Twitter](https://developer.twitter.com/en/docs/tweets/tweet-updates) requires all requests for data on Twitter statuses include the paramater `tweet_mode=extended`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## search query function\n",
    "search_twitter <- function(q, geocode = NULL, \n",
    "                           lang = NULL, \n",
    "                           locale = NULL, \n",
    "                           result_type = \"recent\", \n",
    "                           count = 100, \n",
    "                           until = NULL, \n",
    "                           max_id = NULL, \n",
    "                           include_entities = TRUE) {\n",
    "    ## URL scheme and hostname\n",
    "    base_url <- \"https://api.twitter.com\"\n",
    "    ## include the API version number as part of the path\n",
    "    path <- \"1.1/search/tweets.json\"\n",
    "    ## check result type\n",
    "    if (!result_type %in% c(\"recent\", \"popular\", \"mixed\")) {\n",
    "        stop(\"result_type must be one of recent, popular, or mixed\", \n",
    "            call. = FALSE)\n",
    "    }\n",
    "    ## build query parameters\n",
    "    params <- list(\n",
    "        q = q,\n",
    "        geocode = geocode,\n",
    "        lang = lang,\n",
    "        locale = locale,\n",
    "        result_type = result_type,\n",
    "        count = count,\n",
    "        until = until,\n",
    "        max_id = max_id,\n",
    "        include_entitities = include_entities,\n",
    "        tweet_mode = \"extended\"\n",
    "    )\n",
    "    ## send GET request\n",
    "    httr::GET(base_url, path = path, query = params, \n",
    "              httr::config(token = read_twittertoken()))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## execute search for all tweets mentioning \"rstats\" (this will include hashtags)/\n",
    "rstats <- search_twitter(\"rstats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response [https://api.twitter.com/1.1/search/tweets.json?q=rstats&result_type=recent&count=100&include_entitities=TRUE&tweet_mode=extended]\n",
       "  Date: 2018-01-28 22:25\n",
       "  Status: 200\n",
       "  Content-Type: application/json;charset=utf-8\n",
       "  Size: 663 kB\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## view the response object\n",
    "rstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## parse as text (convert response object to json)\n",
    "js <- httr::content(rstats, as = \"text\", encoding = \"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## convert json character vector to R list\n",
    "d <- jsonlite::fromJSON(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 2\n",
      " $ statuses       :'data.frame':\t100 obs. of  31 variables:\n",
      " $ search_metadata:List of 9\n"
     ]
    }
   ],
   "source": [
    "str(d, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like all the good stuff is in \"statuses\", so let's inspect two levels down in `d$statuses`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t100 obs. of  31 variables:\n",
      " $ created_at               : chr  \"Sun Jan 28 22:24:24 +0000 2018\" \"Sun Jan 28 22:24:12 +0000 2018\" \"Sun Jan 28 22:23:52 +0000 2018\" \"Sun Jan 28 22:23:16 +0000 2018\" ...\n",
      " $ id                       : num  9.58e+17 9.58e+17 9.58e+17 9.58e+17 9.58e+17 ...\n",
      " $ id_str                   : chr  \"957741173598248960\" \"957741123371438082\" \"957741040332492800\" \"957740888142184448\" ...\n",
      " $ full_text                : chr  \"RT @gp_pulipaka: Free eBook: Azure Serverless Computing Cookbook. #BigData #MachineLearning #DataScience #AI #A\"| __truncated__ \"RT @DataCamp: Time series #data in #Rstats: xts cheat sheet - https://t.co/OYN5vi1ez7 #datascience https://t.co/Ettn1iUTVz\" \"RT @gp_pulipaka: Free eBook: Azure Serverless Computing Cookbook. #BigData #MachineLearning #DataScience #AI #A\"| __truncated__ \"RT @DeepSingularity: A Technical Overview of Azure Databricks. #BigData #MachineLearning #DataScience #AI #Anal\"| __truncated__ ...\n",
      " $ truncated                : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ display_text_range       :List of 100\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 122\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 139\n",
      "  ..$ : int  0 149\n",
      "  ..$ : int  0 105\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 128\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 105\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 77\n",
      "  ..$ : int  0 82\n",
      "  ..$ : int  0 82\n",
      "  ..$ : int  0 102\n",
      "  ..$ : int  0 55\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 71\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 172\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 58\n",
      "  ..$ : int  0 100\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 258\n",
      "  ..$ : int  0 105\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 185\n",
      "  ..$ : int  0 55\n",
      "  ..$ : int  0 139\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 88\n",
      "  ..$ : int  0 99\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 99\n",
      "  ..$ : int  0 105\n",
      "  ..$ : int  0 87\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 84\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 135\n",
      "  ..$ : int  0 122\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 166\n",
      "  ..$ : int  0 122\n",
      "  ..$ : int  0 128\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 105\n",
      "  ..$ : int  0 105\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 120\n",
      "  ..$ : int  0 99\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 168\n",
      "  ..$ : int  0 63\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 153\n",
      "  ..$ : int  0 87\n",
      "  ..$ : int  0 87\n",
      "  ..$ : int  0 75\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 139\n",
      "  ..$ : int  0 99\n",
      "  ..$ : int  0 105\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  60 137\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 107\n",
      "  ..$ : int  0 99\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 205\n",
      "  ..$ : int  0 70\n",
      "  ..$ : int  0 144\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 99\n",
      "  ..$ : int  0 129\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 194\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 105\n",
      "  ..$ : int  0 130\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 140\n",
      "  ..$ : int  0 89\n",
      "  .. [list output truncated]\n",
      " $ entities                 :'data.frame':\t100 obs. of  5 variables:\n",
      "  ..$ hashtags     :List of 100\n",
      "  ..$ symbols      :List of 100\n",
      "  ..$ user_mentions:List of 100\n",
      "  ..$ urls         :List of 100\n",
      "  ..$ media        :List of 100\n",
      " $ metadata                 :'data.frame':\t100 obs. of  2 variables:\n",
      "  ..$ iso_language_code: chr  \"en\" \"en\" \"en\" \"en\" ...\n",
      "  ..$ result_type      : chr  \"recent\" \"recent\" \"recent\" \"recent\" ...\n",
      " $ source                   : chr  \"<a href=\\\"https://www.youtube.com/watch?v=kOdzV3B8GWQ\\\" rel=\\\"nofollow\\\">Calcaware</a>\" \"<a href=\\\"http://twitter.com/download/android\\\" rel=\\\"nofollow\\\">Twitter for Android</a>\" \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\" \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\" ...\n",
      " $ in_reply_to_status_id    : num  NA NA NA NA 9.58e+17 ...\n",
      " $ in_reply_to_status_id_str: chr  NA NA NA NA ...\n",
      " $ in_reply_to_user_id      : num  NA NA NA NA 4.24e+08 ...\n",
      " $ in_reply_to_user_id_str  : chr  NA NA NA NA ...\n",
      " $ in_reply_to_screen_name  : chr  NA NA NA NA ...\n",
      " $ user                     :'data.frame':\t100 obs. of  42 variables:\n",
      "  ..$ id                                : num  7.10e+17 3.53e+08 9.44e+17 9.44e+17 4.24e+08 ...\n",
      "  ..$ id_str                            : chr  \"709564705304498176\" \"352726814\" \"944251097480171520\" \"944251097480171520\" ...\n",
      "  ..$ name                              : chr  \"Christopher Burnette\" \"New Urban Grit\" \"Anu\" \"Anu\" ...\n",
      "  ..$ screen_name                       : chr  \"Calcaware\" \"newurbangrit\" \"Anu08801087\" \"Anu08801087\" ...\n",
      "  ..$ location                          : chr  \"Austin, TX\" \"Brooklyn, NYC\" \"\" \"\" ...\n",
      "  ..$ description                       : chr  \"Programmer / Hacker, Problem Solver, Everything Tech\" \"Transportation planning/engineering & data. Taking a stand against car-friendly cities since 2010. Car-less sin\"| __truncated__ \"\" \"\" ...\n",
      "  ..$ url                               : chr  \"https://t.co/RSAJ4kBhQC\" \"http://t.co/GN1NQ68ja7\" NA NA ...\n",
      "  ..$ entities                          :'data.frame':\t100 obs. of  2 variables:\n",
      "  ..$ protected                         : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      "  ..$ followers_count                   : int  5519 195 12 12 1055 356 446 170 12 15 ...\n",
      "  ..$ friends_count                     : int  274 405 11 11 525 1184 710 842 11 127 ...\n",
      "  ..$ listed_count                      : int  515 54 2 2 49 21 36 195 2 11 ...\n",
      "  ..$ created_at                        : chr  \"Tue Mar 15 02:19:43 +0000 2016\" \"Thu Aug 11 00:53:16 +0000 2011\" \"Fri Dec 22 16:59:39 +0000 2017\" \"Fri Dec 22 16:59:39 +0000 2017\" ...\n",
      "  ..$ favourites_count                  : int  114127 132 3 3 23331 135 54661 6292 3 7 ...\n",
      "  ..$ utc_offset                        : int  -28800 -18000 NA NA -28800 0 3600 3600 NA NA ...\n",
      "  ..$ time_zone                         : chr  \"Pacific Time (US & Canada)\" \"Eastern Time (US & Canada)\" NA NA ...\n",
      "  ..$ geo_enabled                       : logi  FALSE FALSE FALSE FALSE TRUE FALSE ...\n",
      "  ..$ verified                          : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      "  ..$ statuses_count                    : int  294393 3895 479 479 11459 188 13387 2318 479 1032 ...\n",
      "  ..$ lang                              : chr  \"en\" \"en\" \"en\" \"en\" ...\n",
      "  ..$ contributors_enabled              : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      "  ..$ is_translator                     : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      "  ..$ is_translation_enabled            : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      "  ..$ profile_background_color          : chr  \"031116\" \"1A1B1F\" \"F5F8FA\" \"F5F8FA\" ...\n",
      "  ..$ profile_background_image_url      : chr  \"http://abs.twimg.com/images/themes/theme14/bg.gif\" \"http://abs.twimg.com/images/themes/theme9/bg.gif\" NA NA ...\n",
      "  ..$ profile_background_image_url_https: chr  \"https://abs.twimg.com/images/themes/theme14/bg.gif\" \"https://abs.twimg.com/images/themes/theme9/bg.gif\" NA NA ...\n",
      "  ..$ profile_background_tile           : logi  TRUE FALSE FALSE FALSE FALSE TRUE ...\n",
      "  ..$ profile_image_url                 : chr  \"http://pbs.twimg.com/profile_images/841210424599109632/eO4g3fSs_normal.jpg\" \"http://pbs.twimg.com/profile_images/1489074699/banksy_park_normal.jpg\" \"http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png\" \"http://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png\" ...\n",
      "  ..$ profile_image_url_https           : chr  \"https://pbs.twimg.com/profile_images/841210424599109632/eO4g3fSs_normal.jpg\" \"https://pbs.twimg.com/profile_images/1489074699/banksy_park_normal.jpg\" \"https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png\" \"https://abs.twimg.com/sticky/default_profile_images/default_profile_normal.png\" ...\n",
      "  ..$ profile_banner_url                : chr  \"https://pbs.twimg.com/profile_banners/709564705304498176/1509117761\" \"https://pbs.twimg.com/profile_banners/352726814/1368111308\" NA NA ...\n",
      "  ..$ profile_link_color                : chr  \"101010\" \"2FC2EF\" \"1DA1F2\" \"1DA1F2\" ...\n",
      "  ..$ profile_sidebar_border_color      : chr  \"000000\" \"181A1E\" \"C0DEED\" \"C0DEED\" ...\n",
      "  ..$ profile_sidebar_fill_color        : chr  \"000000\" \"252429\" \"DDEEF6\" \"DDEEF6\" ...\n",
      "  ..$ profile_text_color                : chr  \"000000\" \"666666\" \"333333\" \"333333\" ...\n",
      "  ..$ profile_use_background_image      : logi  TRUE TRUE TRUE TRUE FALSE TRUE ...\n",
      "  ..$ has_extended_profile              : logi  TRUE FALSE FALSE FALSE TRUE FALSE ...\n",
      "  ..$ default_profile                   : logi  FALSE FALSE TRUE TRUE FALSE FALSE ...\n",
      "  ..$ default_profile_image             : logi  FALSE FALSE TRUE TRUE FALSE FALSE ...\n",
      "  ..$ following                         : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      "  ..$ follow_request_sent               : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      "  ..$ notifications                     : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      "  ..$ translator_type                   : chr  \"none\" \"none\" \"none\" \"none\" ...\n",
      " $ geo                      : logi  NA NA NA NA NA NA ...\n",
      " $ coordinates              : logi  NA NA NA NA NA NA ...\n",
      " $ place                    : logi  NA NA NA NA NA NA ...\n",
      " $ contributors             : logi  NA NA NA NA NA NA ...\n",
      " $ retweeted_status         :'data.frame':\t100 obs. of  30 variables:\n",
      "  ..$ created_at               : chr  \"Sat Jan 27 17:28:02 +0000 2018\" \"Sun Jan 28 19:05:53 +0000 2018\" \"Sat Jan 27 17:28:02 +0000 2018\" \"Sat Jan 27 18:28:01 +0000 2018\" ...\n",
      "  ..$ id                       : num  9.57e+17 9.58e+17 9.57e+17 9.57e+17 NA ...\n",
      "  ..$ id_str                   : chr  \"957304201993957376\" \"957691215746666503\" \"957304201993957376\" \"957319299529625600\" ...\n",
      "  ..$ full_text                : chr  \"Free eBook: Azure Serverless Computing Cookbook. #BigData #MachineLearning #DataScience #AI #Azure #Serverless \"| __truncated__ \"Time series #data in #Rstats: xts cheat sheet - https://t.co/OYN5vi1ez7 #datascience https://t.co/Ettn1iUTVz\" \"Free eBook: Azure Serverless Computing Cookbook. #BigData #MachineLearning #DataScience #AI #Azure #Serverless \"| __truncated__ \"A Technical Overview of Azure Databricks. #BigData #MachineLearning #DataScience #AI #Analytics #HDInsight #Dat\"| __truncated__ ...\n",
      "  ..$ truncated                : logi  FALSE FALSE FALSE FALSE NA FALSE ...\n",
      "  ..$ display_text_range       :List of 100\n",
      "  ..$ entities                 :'data.frame':\t100 obs. of  5 variables:\n",
      "  ..$ extended_entities        :'data.frame':\t100 obs. of  1 variable:\n",
      "  ..$ metadata                 :'data.frame':\t100 obs. of  2 variables:\n",
      "  ..$ source                   : chr  \"<a href=\\\"http://bufferapp.com\\\" rel=\\\"nofollow\\\">Buffer</a>\" \"<a href=\\\"http://meetedgar.com\\\" rel=\\\"nofollow\\\">Meet Edgar</a>\" \"<a href=\\\"http://bufferapp.com\\\" rel=\\\"nofollow\\\">Buffer</a>\" \"<a href=\\\"http://bufferapp.com\\\" rel=\\\"nofollow\\\">Buffer</a>\" ...\n",
      "  ..$ in_reply_to_status_id    : num  NA NA NA NA NA NA NA NA NA NA ...\n",
      "  ..$ in_reply_to_status_id_str: chr  NA NA NA NA ...\n",
      "  ..$ in_reply_to_user_id      : num  NA NA NA NA NA NA NA NA NA NA ...\n",
      "  ..$ in_reply_to_user_id_str  : chr  NA NA NA NA ...\n",
      "  ..$ in_reply_to_screen_name  : chr  NA NA NA NA ...\n",
      "  ..$ user                     :'data.frame':\t100 obs. of  42 variables:\n",
      "  ..$ geo                      : logi  NA NA NA NA NA NA ...\n",
      "  ..$ coordinates              : logi  NA NA NA NA NA NA ...\n",
      "  ..$ place                    : logi  NA NA NA NA NA NA ...\n",
      "  ..$ contributors             : logi  NA NA NA NA NA NA ...\n",
      "  ..$ is_quote_status          : logi  FALSE FALSE FALSE FALSE NA FALSE ...\n",
      "  ..$ retweet_count            : int  18 5 18 12 NA 26 22 13 10 26 ...\n",
      "  ..$ favorite_count           : int  15 9 15 3 NA 44 93 17 6 44 ...\n",
      "  ..$ favorited                : logi  FALSE FALSE FALSE FALSE NA FALSE ...\n",
      "  ..$ retweeted                : logi  FALSE FALSE FALSE FALSE NA FALSE ...\n",
      "  ..$ possibly_sensitive       : logi  FALSE FALSE FALSE FALSE NA FALSE ...\n",
      "  ..$ lang                     : chr  \"en\" \"en\" \"en\" \"en\" ...\n",
      "  ..$ quoted_status_id         : num  NA NA NA NA NA NA NA NA NA NA ...\n",
      "  ..$ quoted_status_id_str     : chr  NA NA NA NA ...\n",
      "  ..$ quoted_status            :'data.frame':\t100 obs. of  27 variables:\n",
      " $ is_quote_status          : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ retweet_count            : int  18 5 18 12 0 26 22 13 10 26 ...\n",
      " $ favorite_count           : int  0 0 0 0 1 0 0 0 0 0 ...\n",
      " $ favorited                : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ retweeted                : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ lang                     : chr  \"en\" \"en\" \"en\" \"en\" ...\n",
      " $ extended_entities        :'data.frame':\t100 obs. of  1 variable:\n",
      "  ..$ media:List of 100\n",
      " $ possibly_sensitive       : logi  NA FALSE NA NA FALSE FALSE ...\n",
      " $ quoted_status_id         : num  NA NA NA NA NA NA NA NA NA NA ...\n",
      " $ quoted_status_id_str     : chr  NA NA NA NA ...\n",
      " $ quoted_status            :'data.frame':\t100 obs. of  27 variables:\n",
      "  ..$ created_at               : chr  NA NA NA NA ...\n",
      "  ..$ id                       : num  NA NA NA NA NA NA NA NA NA NA ...\n",
      "  ..$ id_str                   : chr  NA NA NA NA ...\n",
      "  ..$ full_text                : chr  NA NA NA NA ...\n",
      "  ..$ truncated                : logi  NA NA NA NA NA NA ...\n",
      "  ..$ display_text_range       :List of 100\n",
      "  ..$ entities                 :'data.frame':\t100 obs. of  5 variables:\n",
      "  ..$ extended_entities        :'data.frame':\t100 obs. of  1 variable:\n",
      "  ..$ metadata                 :'data.frame':\t100 obs. of  2 variables:\n",
      "  ..$ source                   : chr  NA NA NA NA ...\n",
      "  ..$ in_reply_to_status_id    : logi  NA NA NA NA NA NA ...\n",
      "  ..$ in_reply_to_status_id_str: logi  NA NA NA NA NA NA ...\n",
      "  ..$ in_reply_to_user_id      : logi  NA NA NA NA NA NA ...\n",
      "  ..$ in_reply_to_user_id_str  : logi  NA NA NA NA NA NA ...\n",
      "  ..$ in_reply_to_screen_name  : logi  NA NA NA NA NA NA ...\n",
      "  ..$ user                     :'data.frame':\t100 obs. of  42 variables:\n",
      "  ..$ geo                      : logi  NA NA NA NA NA NA ...\n",
      "  ..$ coordinates              : logi  NA NA NA NA NA NA ...\n",
      "  ..$ place                    : logi  NA NA NA NA NA NA ...\n",
      "  ..$ contributors             : logi  NA NA NA NA NA NA ...\n",
      "  ..$ is_quote_status          : logi  NA NA NA NA NA NA ...\n",
      "  ..$ retweet_count            : int  NA NA NA NA NA NA NA NA NA NA ...\n",
      "  ..$ favorite_count           : int  NA NA NA NA NA NA NA NA NA NA ...\n",
      "  ..$ favorited                : logi  NA NA NA NA NA NA ...\n",
      "  ..$ retweeted                : logi  NA NA NA NA NA NA ...\n",
      "  ..$ possibly_sensitive       : logi  NA NA NA NA NA NA ...\n",
      "  ..$ lang                     : chr  NA NA NA NA ...\n"
     ]
    }
   ],
   "source": [
    "df <- d$statuses\n",
    "str(df, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good news is that we have a lot of data. Not just the text of the tweets, but all sorts of other meta data. \n",
    "\n",
    "The bad news is that to conduct analysis on the data, we typically want to wrangle it into a data frame. For example, what if I wanted to see if the number of hashtags was predicted by the source of the tweet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 100\n",
      " $ :'data.frame':\t7 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:7] \"BigData\" \"MachineLearning\" \"DataScience\" \"AI\" ...\n",
      "  ..$ indices:List of 7\n",
      " $ :'data.frame':\t3 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:3] \"data\" \"Rstats\" \"datascience\"\n",
      "  ..$ indices:List of 3\n",
      " $ :'data.frame':\t7 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:7] \"BigData\" \"MachineLearning\" \"DataScience\" \"AI\" ...\n",
      "  ..$ indices:List of 7\n",
      " $ :'data.frame':\t7 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:7] \"BigData\" \"MachineLearning\" \"DataScience\" \"AI\" ...\n",
      "  ..$ indices:List of 7\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"DataScience\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t3 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:3] \"TidyData\" \"rstats\" \"DataScience\"\n",
      "  ..$ indices:List of 3\n",
      " $ :'data.frame':\t5 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:5] \"BigData\" \"DeepLearning\" \"MachineLearning\" \"DataScience\" ...\n",
      "  ..$ indices:List of 5\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"DataScience\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t3 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:3] \"rstats\" \"dataviz\" \"visualization\"\n",
      "  ..$ indices:List of 3\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"helpdatascientist\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"VR\" \"DataViz\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"postgres\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"RSTATS\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"SundayDataReading\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"Rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"Rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t5 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:5] \"SundayDataReading\" \"MachineLerning\" \"DataScience\" \"AI\" ...\n",
      "  ..$ indices:List of 5\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"RSTATS\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"DataScience\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"Rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t4 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:4] \"rstats\" \"postgres\" \"event\" \"SQL\"\n",
      "  ..$ indices:List of 4\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"DataScience\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t6 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:6] \"VR\" \"DataViz\" \"WebVR\" \"rstats\" ...\n",
      "  ..$ indices:List of 6\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"ddtx18\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"datadaytexas\" \"rstats\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"tidyverse\" \"rstats\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"DeepLearning\" \"rstats\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"DeepLearning\" \"rstats\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"DataScience\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"womeninstem\" \"rstats\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"tidyverse\" \"rstats\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"phdchat\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"macOS\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"DeepLearning\" \"rstats\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t3 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:3] \"data\" \"Rstats\" \"datascience\"\n",
      "  ..$ indices:List of 3\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"DataScience\" \"AI\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t3 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:3] \"rstats\" \"dataviz\" \"visualization\"\n",
      "  ..$ indices:List of 3\n",
      " $ :'data.frame':\t7 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:7] \"DataScience\" \"AI\" \"ML\" \"rstats\" ...\n",
      "  ..$ indices:List of 7\n",
      " $ :'data.frame':\t3 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:3] \"data\" \"Rstats\" \"datascience\"\n",
      "  ..$ indices:List of 3\n",
      " $ :'data.frame':\t3 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:3] \"TidyData\" \"rstats\" \"DataScience\"\n",
      "  ..$ indices:List of 3\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"DataScience\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"DataScience\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t4 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:4] \"MachineLearning\" \"Algorithms\" \"Python\" \"BigData\"\n",
      "  ..$ indices:List of 4\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"DeepLearning\" \"rstats\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"DeepLearning\" \"rstats\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"macOS\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"phdchat\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"tidyverse\" \"rstats\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"womeninstem\" \"rstats\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"womeninstem\" \"rstats\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"womeninstem\" \"rstats\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t3 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:3] \"Congaree\" \"rstats\" \"leaflet\"\n",
      "  ..$ indices:List of 3\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"DeepLearning\" \"rstats\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"DataScience\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"Woodthrush\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"reproducibleresearch\" \"rstats\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"Rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t4 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:4] \"rstats\" \"tidyverse\" \"Education\" \"Teachers\"\n",
      "  ..$ indices:List of 4\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"DeepLearning\" \"rstats\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t3 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:3] \"BigData\" \"DeepLearning\" \"MachineLearning\"\n",
      "  ..$ indices:List of 3\n",
      " $ :'data.frame':\t4 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:4] \"ddj\" \"RStats\" \"AusOpen\" \"RF20\"\n",
      "  ..$ indices:List of 4\n",
      " $ :'data.frame':\t7 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:7] \"BigData\" \"MachineLearning\" \"DataScience\" \"AI\" ...\n",
      "  ..$ indices:List of 7\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"Rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"DeepLearning\" \"rstats\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"Rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"RStats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"RStats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t8 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:8] \"BigData\" \"MachineLearning\" \"DataScience\" \"Azure\" ...\n",
      "  ..$ indices:List of 8\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"DataScience\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"DDTX18\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t0 obs. of  0 variables\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"Rstats\"\n",
      "  ..$ indices:List of 1\n",
      " $ :'data.frame':\t2 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:2] \"rstats\" \"diffobj\"\n",
      "  ..$ indices:List of 2\n",
      " $ :'data.frame':\t5 obs. of  2 variables:\n",
      "  ..$ text   : chr [1:5] \"BigData\" \"DeepLearning\" \"MachineLearning\" \"DataScience\" ...\n",
      "  ..$ indices:List of 5\n",
      " $ :'data.frame':\t1 obs. of  2 variables:\n",
      "  ..$ text   : chr \"Rstats\"\n",
      "  ..$ indices:List of 1\n",
      "  [list output truncated]\n"
     ]
    }
   ],
   "source": [
    "str(df$entities$hashtags, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the hashtags object consist of 100 data frames, some of which have zero observations. So, we'll have to clean this up. I've done just that in the code below by first extracting the text of hashtags and then by replacing the NULL returns (data frames with zero observations and, consequently, no \"text\" variable) with a NA [of class character] value. The list of hashtags is then added to the `df` data frame, using the `I()` function to tell R that we know it's a recursive (more than one observation per) list. Finally, the number of hashtags are counted and added to the data frame as a variable named `hashtag_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li><ol class=list-inline>\n",
       "\t<li>'BigData'</li>\n",
       "\t<li>'MachineLearning'</li>\n",
       "\t<li>'DataScience'</li>\n",
       "\t<li>'AI'</li>\n",
       "\t<li>'Azure'</li>\n",
       "\t<li>'Serverless'</li>\n",
       "\t<li>'IoT'</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li><ol class=list-inline>\n",
       "\t<li>'data'</li>\n",
       "\t<li>'Rstats'</li>\n",
       "\t<li>'datascience'</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li><ol class=list-inline>\n",
       "\t<li>'BigData'</li>\n",
       "\t<li>'MachineLearning'</li>\n",
       "\t<li>'DataScience'</li>\n",
       "\t<li>'AI'</li>\n",
       "\t<li>'Azure'</li>\n",
       "\t<li>'Serverless'</li>\n",
       "\t<li>'IoT'</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li><ol class=list-inline>\n",
       "\t<li>'BigData'</li>\n",
       "\t<li>'MachineLearning'</li>\n",
       "\t<li>'DataScience'</li>\n",
       "\t<li>'AI'</li>\n",
       "\t<li>'Analytics'</li>\n",
       "\t<li>'HDInsight'</li>\n",
       "\t<li>'DataLakes'</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li>'rstats'</li>\n",
       "\t<li><ol class=list-inline>\n",
       "\t<li>'rstats'</li>\n",
       "\t<li>'DataScience'</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li>'rstats'</li>\n",
       "\t<li><ol class=list-inline>\n",
       "\t<li>'TidyData'</li>\n",
       "\t<li>'rstats'</li>\n",
       "\t<li>'DataScience'</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li><ol class=list-inline>\n",
       "\t<li>'BigData'</li>\n",
       "\t<li>'DeepLearning'</li>\n",
       "\t<li>'MachineLearning'</li>\n",
       "\t<li>'DataScience'</li>\n",
       "\t<li>'AI'</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li><ol class=list-inline>\n",
       "\t<li>'rstats'</li>\n",
       "\t<li>'DataScience'</li>\n",
       "</ol>\n",
       "</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'BigData'\n",
       "\\item 'MachineLearning'\n",
       "\\item 'DataScience'\n",
       "\\item 'AI'\n",
       "\\item 'Azure'\n",
       "\\item 'Serverless'\n",
       "\\item 'IoT'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'data'\n",
       "\\item 'Rstats'\n",
       "\\item 'datascience'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'BigData'\n",
       "\\item 'MachineLearning'\n",
       "\\item 'DataScience'\n",
       "\\item 'AI'\n",
       "\\item 'Azure'\n",
       "\\item 'Serverless'\n",
       "\\item 'IoT'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'BigData'\n",
       "\\item 'MachineLearning'\n",
       "\\item 'DataScience'\n",
       "\\item 'AI'\n",
       "\\item 'Analytics'\n",
       "\\item 'HDInsight'\n",
       "\\item 'DataLakes'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item 'rstats'\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'rstats'\n",
       "\\item 'DataScience'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item 'rstats'\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'TidyData'\n",
       "\\item 'rstats'\n",
       "\\item 'DataScience'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'BigData'\n",
       "\\item 'DeepLearning'\n",
       "\\item 'MachineLearning'\n",
       "\\item 'DataScience'\n",
       "\\item 'AI'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'rstats'\n",
       "\\item 'DataScience'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. 1. 'BigData'\n",
       "2. 'MachineLearning'\n",
       "3. 'DataScience'\n",
       "4. 'AI'\n",
       "5. 'Azure'\n",
       "6. 'Serverless'\n",
       "7. 'IoT'\n",
       "\n",
       "\n",
       "\n",
       "2. 1. 'data'\n",
       "2. 'Rstats'\n",
       "3. 'datascience'\n",
       "\n",
       "\n",
       "\n",
       "3. 1. 'BigData'\n",
       "2. 'MachineLearning'\n",
       "3. 'DataScience'\n",
       "4. 'AI'\n",
       "5. 'Azure'\n",
       "6. 'Serverless'\n",
       "7. 'IoT'\n",
       "\n",
       "\n",
       "\n",
       "4. 1. 'BigData'\n",
       "2. 'MachineLearning'\n",
       "3. 'DataScience'\n",
       "4. 'AI'\n",
       "5. 'Analytics'\n",
       "6. 'HDInsight'\n",
       "7. 'DataLakes'\n",
       "\n",
       "\n",
       "\n",
       "5. 'rstats'\n",
       "6. 1. 'rstats'\n",
       "2. 'DataScience'\n",
       "\n",
       "\n",
       "\n",
       "7. 'rstats'\n",
       "8. 1. 'TidyData'\n",
       "2. 'rstats'\n",
       "3. 'DataScience'\n",
       "\n",
       "\n",
       "\n",
       "9. 1. 'BigData'\n",
       "2. 'DeepLearning'\n",
       "3. 'MachineLearning'\n",
       "4. 'DataScience'\n",
       "5. 'AI'\n",
       "\n",
       "\n",
       "\n",
       "10. 1. 'rstats'\n",
       "2. 'DataScience'\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "[1] \"BigData\"         \"MachineLearning\" \"DataScience\"     \"AI\"             \n",
       "[5] \"Azure\"           \"Serverless\"      \"IoT\"            \n",
       "\n",
       "[[2]]\n",
       "[1] \"data\"        \"Rstats\"      \"datascience\"\n",
       "\n",
       "[[3]]\n",
       "[1] \"BigData\"         \"MachineLearning\" \"DataScience\"     \"AI\"             \n",
       "[5] \"Azure\"           \"Serverless\"      \"IoT\"            \n",
       "\n",
       "[[4]]\n",
       "[1] \"BigData\"         \"MachineLearning\" \"DataScience\"     \"AI\"             \n",
       "[5] \"Analytics\"       \"HDInsight\"       \"DataLakes\"      \n",
       "\n",
       "[[5]]\n",
       "[1] \"rstats\"\n",
       "\n",
       "[[6]]\n",
       "[1] \"rstats\"      \"DataScience\"\n",
       "\n",
       "[[7]]\n",
       "[1] \"rstats\"\n",
       "\n",
       "[[8]]\n",
       "[1] \"TidyData\"    \"rstats\"      \"DataScience\"\n",
       "\n",
       "[[9]]\n",
       "[1] \"BigData\"         \"DeepLearning\"    \"MachineLearning\" \"DataScience\"    \n",
       "[5] \"AI\"             \n",
       "\n",
       "[[10]]\n",
       "[1] \"rstats\"      \"DataScience\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## extract text of hashtags\n",
    "hashtags <- lapply(df$entities$hashtags, \"[[\", \"text\")\n",
    "hashtags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## replace nulls with missing\n",
    "hashtags[lengths(hashtags) == 0L] <- NA_character_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol>\n",
       "\t<li><ol class=list-inline>\n",
       "\t<li>'BigData'</li>\n",
       "\t<li>'MachineLearning'</li>\n",
       "\t<li>'DataScience'</li>\n",
       "\t<li>'AI'</li>\n",
       "\t<li>'Azure'</li>\n",
       "\t<li>'Serverless'</li>\n",
       "\t<li>'IoT'</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li><ol class=list-inline>\n",
       "\t<li>'data'</li>\n",
       "\t<li>'Rstats'</li>\n",
       "\t<li>'datascience'</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li><ol class=list-inline>\n",
       "\t<li>'BigData'</li>\n",
       "\t<li>'MachineLearning'</li>\n",
       "\t<li>'DataScience'</li>\n",
       "\t<li>'AI'</li>\n",
       "\t<li>'Azure'</li>\n",
       "\t<li>'Serverless'</li>\n",
       "\t<li>'IoT'</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li><ol class=list-inline>\n",
       "\t<li>'BigData'</li>\n",
       "\t<li>'MachineLearning'</li>\n",
       "\t<li>'DataScience'</li>\n",
       "\t<li>'AI'</li>\n",
       "\t<li>'Analytics'</li>\n",
       "\t<li>'HDInsight'</li>\n",
       "\t<li>'DataLakes'</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li>'rstats'</li>\n",
       "\t<li><ol class=list-inline>\n",
       "\t<li>'rstats'</li>\n",
       "\t<li>'DataScience'</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li>'rstats'</li>\n",
       "\t<li><ol class=list-inline>\n",
       "\t<li>'TidyData'</li>\n",
       "\t<li>'rstats'</li>\n",
       "\t<li>'DataScience'</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li><ol class=list-inline>\n",
       "\t<li>'BigData'</li>\n",
       "\t<li>'DeepLearning'</li>\n",
       "\t<li>'MachineLearning'</li>\n",
       "\t<li>'DataScience'</li>\n",
       "\t<li>'AI'</li>\n",
       "</ol>\n",
       "</li>\n",
       "\t<li><ol class=list-inline>\n",
       "\t<li>'rstats'</li>\n",
       "\t<li>'DataScience'</li>\n",
       "</ol>\n",
       "</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate}\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'BigData'\n",
       "\\item 'MachineLearning'\n",
       "\\item 'DataScience'\n",
       "\\item 'AI'\n",
       "\\item 'Azure'\n",
       "\\item 'Serverless'\n",
       "\\item 'IoT'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'data'\n",
       "\\item 'Rstats'\n",
       "\\item 'datascience'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'BigData'\n",
       "\\item 'MachineLearning'\n",
       "\\item 'DataScience'\n",
       "\\item 'AI'\n",
       "\\item 'Azure'\n",
       "\\item 'Serverless'\n",
       "\\item 'IoT'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'BigData'\n",
       "\\item 'MachineLearning'\n",
       "\\item 'DataScience'\n",
       "\\item 'AI'\n",
       "\\item 'Analytics'\n",
       "\\item 'HDInsight'\n",
       "\\item 'DataLakes'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item 'rstats'\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'rstats'\n",
       "\\item 'DataScience'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item 'rstats'\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'TidyData'\n",
       "\\item 'rstats'\n",
       "\\item 'DataScience'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'BigData'\n",
       "\\item 'DeepLearning'\n",
       "\\item 'MachineLearning'\n",
       "\\item 'DataScience'\n",
       "\\item 'AI'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item \\begin{enumerate*}\n",
       "\\item 'rstats'\n",
       "\\item 'DataScience'\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\end{enumerate}\n"
      ],
      "text/markdown": [
       "1. 1. 'BigData'\n",
       "2. 'MachineLearning'\n",
       "3. 'DataScience'\n",
       "4. 'AI'\n",
       "5. 'Azure'\n",
       "6. 'Serverless'\n",
       "7. 'IoT'\n",
       "\n",
       "\n",
       "\n",
       "2. 1. 'data'\n",
       "2. 'Rstats'\n",
       "3. 'datascience'\n",
       "\n",
       "\n",
       "\n",
       "3. 1. 'BigData'\n",
       "2. 'MachineLearning'\n",
       "3. 'DataScience'\n",
       "4. 'AI'\n",
       "5. 'Azure'\n",
       "6. 'Serverless'\n",
       "7. 'IoT'\n",
       "\n",
       "\n",
       "\n",
       "4. 1. 'BigData'\n",
       "2. 'MachineLearning'\n",
       "3. 'DataScience'\n",
       "4. 'AI'\n",
       "5. 'Analytics'\n",
       "6. 'HDInsight'\n",
       "7. 'DataLakes'\n",
       "\n",
       "\n",
       "\n",
       "5. 'rstats'\n",
       "6. 1. 'rstats'\n",
       "2. 'DataScience'\n",
       "\n",
       "\n",
       "\n",
       "7. 'rstats'\n",
       "8. 1. 'TidyData'\n",
       "2. 'rstats'\n",
       "3. 'DataScience'\n",
       "\n",
       "\n",
       "\n",
       "9. 1. 'BigData'\n",
       "2. 'DeepLearning'\n",
       "3. 'MachineLearning'\n",
       "4. 'DataScience'\n",
       "5. 'AI'\n",
       "\n",
       "\n",
       "\n",
       "10. 1. 'rstats'\n",
       "2. 'DataScience'\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[[1]]\n",
       "[1] \"BigData\"         \"MachineLearning\" \"DataScience\"     \"AI\"             \n",
       "[5] \"Azure\"           \"Serverless\"      \"IoT\"            \n",
       "\n",
       "[[2]]\n",
       "[1] \"data\"        \"Rstats\"      \"datascience\"\n",
       "\n",
       "[[3]]\n",
       "[1] \"BigData\"         \"MachineLearning\" \"DataScience\"     \"AI\"             \n",
       "[5] \"Azure\"           \"Serverless\"      \"IoT\"            \n",
       "\n",
       "[[4]]\n",
       "[1] \"BigData\"         \"MachineLearning\" \"DataScience\"     \"AI\"             \n",
       "[5] \"Analytics\"       \"HDInsight\"       \"DataLakes\"      \n",
       "\n",
       "[[5]]\n",
       "[1] \"rstats\"\n",
       "\n",
       "[[6]]\n",
       "[1] \"rstats\"      \"DataScience\"\n",
       "\n",
       "[[7]]\n",
       "[1] \"rstats\"\n",
       "\n",
       "[[8]]\n",
       "[1] \"TidyData\"    \"rstats\"      \"DataScience\"\n",
       "\n",
       "[[9]]\n",
       "[1] \"BigData\"         \"DeepLearning\"    \"MachineLearning\" \"DataScience\"    \n",
       "[5] \"AI\"             \n",
       "\n",
       "[[10]]\n",
       "[1] \"rstats\"      \"DataScience\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hashtags[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1]]\n",
       "[1] \"BigData\"         \"MachineLearning\" \"DataScience\"     \"AI\"             \n",
       "[5] \"Azure\"           \"Serverless\"      \"IoT\"            \n",
       "\n",
       "[[2]]\n",
       "[1] \"data\"        \"Rstats\"      \"datascience\"\n",
       "\n",
       "[[3]]\n",
       "[1] \"BigData\"         \"MachineLearning\" \"DataScience\"     \"AI\"             \n",
       "[5] \"Azure\"           \"Serverless\"      \"IoT\"            \n",
       "\n",
       "[[4]]\n",
       "[1] \"BigData\"         \"MachineLearning\" \"DataScience\"     \"AI\"             \n",
       "[5] \"Analytics\"       \"HDInsight\"       \"DataLakes\"      \n",
       "\n",
       "[[5]]\n",
       "[1] \"rstats\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## add to df object\n",
    "df$hashtags <- I(hashtags)\n",
    "df$hashtags[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>7</li>\n",
       "\t<li>3</li>\n",
       "\t<li>7</li>\n",
       "\t<li>7</li>\n",
       "\t<li>1</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 7\n",
       "\\item 3\n",
       "\\item 7\n",
       "\\item 7\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 7\n",
       "2. 3\n",
       "3. 7\n",
       "4. 7\n",
       "5. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 7 3 7 7 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## calculate number of hashtags\n",
    "df$hashtag_count <- lengths(hashtags)\n",
    "df$hashtag_count[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'created_at'</li>\n",
       "\t<li>'id'</li>\n",
       "\t<li>'id_str'</li>\n",
       "\t<li>'full_text'</li>\n",
       "\t<li>'truncated'</li>\n",
       "\t<li>'display_text_range'</li>\n",
       "\t<li>'entities'</li>\n",
       "\t<li>'metadata'</li>\n",
       "\t<li>'source'</li>\n",
       "\t<li>'in_reply_to_status_id'</li>\n",
       "\t<li>'in_reply_to_status_id_str'</li>\n",
       "\t<li>'in_reply_to_user_id'</li>\n",
       "\t<li>'in_reply_to_user_id_str'</li>\n",
       "\t<li>'in_reply_to_screen_name'</li>\n",
       "\t<li>'user'</li>\n",
       "\t<li>'geo'</li>\n",
       "\t<li>'coordinates'</li>\n",
       "\t<li>'place'</li>\n",
       "\t<li>'contributors'</li>\n",
       "\t<li>'retweeted_status'</li>\n",
       "\t<li>'is_quote_status'</li>\n",
       "\t<li>'retweet_count'</li>\n",
       "\t<li>'favorite_count'</li>\n",
       "\t<li>'favorited'</li>\n",
       "\t<li>'retweeted'</li>\n",
       "\t<li>'lang'</li>\n",
       "\t<li>'extended_entities'</li>\n",
       "\t<li>'possibly_sensitive'</li>\n",
       "\t<li>'quoted_status_id'</li>\n",
       "\t<li>'quoted_status_id_str'</li>\n",
       "\t<li>'quoted_status'</li>\n",
       "\t<li>'hashtags'</li>\n",
       "\t<li>'hashtag_count'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'created\\_at'\n",
       "\\item 'id'\n",
       "\\item 'id\\_str'\n",
       "\\item 'full\\_text'\n",
       "\\item 'truncated'\n",
       "\\item 'display\\_text\\_range'\n",
       "\\item 'entities'\n",
       "\\item 'metadata'\n",
       "\\item 'source'\n",
       "\\item 'in\\_reply\\_to\\_status\\_id'\n",
       "\\item 'in\\_reply\\_to\\_status\\_id\\_str'\n",
       "\\item 'in\\_reply\\_to\\_user\\_id'\n",
       "\\item 'in\\_reply\\_to\\_user\\_id\\_str'\n",
       "\\item 'in\\_reply\\_to\\_screen\\_name'\n",
       "\\item 'user'\n",
       "\\item 'geo'\n",
       "\\item 'coordinates'\n",
       "\\item 'place'\n",
       "\\item 'contributors'\n",
       "\\item 'retweeted\\_status'\n",
       "\\item 'is\\_quote\\_status'\n",
       "\\item 'retweet\\_count'\n",
       "\\item 'favorite\\_count'\n",
       "\\item 'favorited'\n",
       "\\item 'retweeted'\n",
       "\\item 'lang'\n",
       "\\item 'extended\\_entities'\n",
       "\\item 'possibly\\_sensitive'\n",
       "\\item 'quoted\\_status\\_id'\n",
       "\\item 'quoted\\_status\\_id\\_str'\n",
       "\\item 'quoted\\_status'\n",
       "\\item 'hashtags'\n",
       "\\item 'hashtag\\_count'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'created_at'\n",
       "2. 'id'\n",
       "3. 'id_str'\n",
       "4. 'full_text'\n",
       "5. 'truncated'\n",
       "6. 'display_text_range'\n",
       "7. 'entities'\n",
       "8. 'metadata'\n",
       "9. 'source'\n",
       "10. 'in_reply_to_status_id'\n",
       "11. 'in_reply_to_status_id_str'\n",
       "12. 'in_reply_to_user_id'\n",
       "13. 'in_reply_to_user_id_str'\n",
       "14. 'in_reply_to_screen_name'\n",
       "15. 'user'\n",
       "16. 'geo'\n",
       "17. 'coordinates'\n",
       "18. 'place'\n",
       "19. 'contributors'\n",
       "20. 'retweeted_status'\n",
       "21. 'is_quote_status'\n",
       "22. 'retweet_count'\n",
       "23. 'favorite_count'\n",
       "24. 'favorited'\n",
       "25. 'retweeted'\n",
       "26. 'lang'\n",
       "27. 'extended_entities'\n",
       "28. 'possibly_sensitive'\n",
       "29. 'quoted_status_id'\n",
       "30. 'quoted_status_id_str'\n",
       "31. 'quoted_status'\n",
       "32. 'hashtags'\n",
       "33. 'hashtag_count'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"created_at\"                \"id\"                       \n",
       " [3] \"id_str\"                    \"full_text\"                \n",
       " [5] \"truncated\"                 \"display_text_range\"       \n",
       " [7] \"entities\"                  \"metadata\"                 \n",
       " [9] \"source\"                    \"in_reply_to_status_id\"    \n",
       "[11] \"in_reply_to_status_id_str\" \"in_reply_to_user_id\"      \n",
       "[13] \"in_reply_to_user_id_str\"   \"in_reply_to_screen_name\"  \n",
       "[15] \"user\"                      \"geo\"                      \n",
       "[17] \"coordinates\"               \"place\"                    \n",
       "[19] \"contributors\"              \"retweeted_status\"         \n",
       "[21] \"is_quote_status\"           \"retweet_count\"            \n",
       "[23] \"favorite_count\"            \"favorited\"                \n",
       "[25] \"retweeted\"                 \"lang\"                     \n",
       "[27] \"extended_entities\"         \"possibly_sensitive\"       \n",
       "[29] \"quoted_status_id\"          \"quoted_status_id_str\"     \n",
       "[31] \"quoted_status\"             \"hashtags\"                 \n",
       "[33] \"hashtag_count\"            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'&lt;a href=\"https://www.youtube.com/watch?v=kOdzV3B8GWQ\" rel=\"nofollow\"&gt;Calcaware&lt;/a&gt;'</li>\n",
       "\t<li>'&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;'</li>\n",
       "\t<li>'&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;'</li>\n",
       "\t<li>'&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;'</li>\n",
       "\t<li>'&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Twitter Web Client&lt;/a&gt;'</li>\n",
       "\t<li>'&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '<a href=\"https://www.youtube.com/watch?v=kOdzV3B8GWQ\" rel=\"nofollow\">Calcaware</a>'\n",
       "\\item '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>'\n",
       "\\item '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>'\n",
       "\\item '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>'\n",
       "\\item '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>'\n",
       "\\item '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '&lt;a href=\"https://www.youtube.com/watch?v=kOdzV3B8GWQ\" rel=\"nofollow\"&gt;Calcaware&lt;/a&gt;'\n",
       "2. '&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;'\n",
       "3. '&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;'\n",
       "4. '&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;'\n",
       "5. '&lt;a href=\"http://twitter.com\" rel=\"nofollow\"&gt;Twitter Web Client&lt;/a&gt;'\n",
       "6. '&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"<a href=\\\"https://www.youtube.com/watch?v=kOdzV3B8GWQ\\\" rel=\\\"nofollow\\\">Calcaware</a>\"  \n",
       "[2] \"<a href=\\\"http://twitter.com/download/android\\\" rel=\\\"nofollow\\\">Twitter for Android</a>\"\n",
       "[3] \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\"  \n",
       "[4] \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\"  \n",
       "[5] \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\"                  \n",
       "[6] \"<a href=\\\"http://twitter.com/download/android\\\" rel=\\\"nofollow\\\">Twitter for Android</a>\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(df$source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source includes html code. Fortunately, we can extract the key text with relative ease using a regular expression like the one below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df$source <- stringr::str_extract(df$source, \"(?<=\\\\>)[^<]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'Calcaware'</li>\n",
       "\t<li>'Twitter for Android'</li>\n",
       "\t<li>'Twitter for iPhone'</li>\n",
       "\t<li>'Twitter for iPhone'</li>\n",
       "\t<li>'Twitter Web Client'</li>\n",
       "\t<li>'Twitter for Android'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Calcaware'\n",
       "\\item 'Twitter for Android'\n",
       "\\item 'Twitter for iPhone'\n",
       "\\item 'Twitter for iPhone'\n",
       "\\item 'Twitter Web Client'\n",
       "\\item 'Twitter for Android'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Calcaware'\n",
       "2. 'Twitter for Android'\n",
       "3. 'Twitter for iPhone'\n",
       "4. 'Twitter for iPhone'\n",
       "5. 'Twitter Web Client'\n",
       "6. 'Twitter for Android'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"Calcaware\"           \"Twitter for Android\" \"Twitter for iPhone\" \n",
       "[4] \"Twitter for iPhone\"  \"Twitter Web Client\"  \"Twitter for Android\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(df$source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've cleaned up these variables, let's run poisson regression to analyze the source as a predictor of the count variable representing the number of hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = hashtag_count ~ source, family = poisson, data = df)\n",
       "\n",
       "Deviance Residuals: \n",
       "    Min       1Q   Median       3Q      Max  \n",
       "-1.5794  -0.6149   0.0000   0.2660   2.6956  \n",
       "\n",
       "Coefficients:\n",
       "                                Estimate Std. Error z value Pr(>|z|)    \n",
       "(Intercept)                    1.253e+00  3.780e-01   3.314 0.000918 ***\n",
       "sourceCalcaware                6.931e-01  5.345e-01   1.297 0.194714    \n",
       "sourceCRANberries Feed        -1.253e+00  6.901e-01  -1.815 0.069458 .  \n",
       "sourceFenix 2                 -1.253e+00  1.069e+00  -1.172 0.241256    \n",
       "sourceMachine learning Bot 6  -5.596e-01  8.018e-01  -0.698 0.485200    \n",
       "sourceNode RED                -5.596e-01  8.018e-01  -0.698 0.485200    \n",
       "sourcePaper.li                -5.596e-01  8.018e-01  -0.698 0.485200    \n",
       "sourceRight Relevance         -1.253e+00  1.069e+00  -1.172 0.241256    \n",
       "sourceRoundTeam               -5.596e-01  8.018e-01  -0.698 0.485200    \n",
       "sourceRstats1234              -7.538e-01  4.226e-01  -1.784 0.074464 .  \n",
       "sourcertapp315156161          -5.596e-01  8.018e-01  -0.698 0.485200    \n",
       "sourceTweetbot for i<U+039F>S -8.473e-01  6.901e-01  -1.228 0.219503    \n",
       "sourceTweetbot for Mac        -1.253e+00  1.069e+00  -1.172 0.241256    \n",
       "sourceTwitter for Android     -8.065e-01  4.276e-01  -1.886 0.059299 .  \n",
       "sourceTwitter for iPad        -5.596e-01  8.018e-01  -0.698 0.485200    \n",
       "sourceTwitter for iPhone      -1.542e-01  3.934e-01  -0.392 0.695173    \n",
       "sourceTwitter for Mac         -1.542e-01  6.901e-01  -0.223 0.823235    \n",
       "sourceTwitter Lite             1.135e-14  5.345e-01   0.000 1.000000    \n",
       "sourceTwitter Web Client      -5.322e-01  4.122e-01  -1.291 0.196615    \n",
       "sourceZippylab4               -5.596e-01  8.018e-01  -0.698 0.485200    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "(Dispersion parameter for poisson family taken to be 1)\n",
       "\n",
       "    Null deviance: 95.039  on 99  degrees of freedom\n",
       "Residual deviance: 66.643  on 80  degrees of freedom\n",
       "AIC: 360.42\n",
       "\n",
       "Number of Fisher Scoring iterations: 5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## poisson regression model\n",
    "m1 <- glm(hashtag_count ~ source, df, family = poisson)\n",
    "\n",
    "## summarize results\n",
    "summary(m1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
