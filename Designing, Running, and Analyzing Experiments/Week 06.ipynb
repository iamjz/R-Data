{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "So far, we've considered analysis of vairance and nonparametric tests for between subject factors only, where each subject only gets one level (or one treatment) of all the possible level of a factor. \n",
    "\n",
    "Now let's consider within-subjects factors and here's the scenario we'll work for from..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's say 20 subjects interact with a smartphone contacts manager to find a set of contacts that they're assigned to look up and they do this initially in 2 ways. These 20 subjects each use 2 techniques. One is searching, typing text, and looking through the context manager that way/ And the other technique they use is scrolling. Just scrolling a list and visually looking for contacts in the list. \n",
    "\n",
    "Later, we'll add a third technique they'll use, which would be voice search. Sepaking the name of contacts and trying to look them up that way. Of course, this is just fictitious data for our use in this course. \n",
    "\n",
    "The things we measure will be total time and number of selection errors. So we're measuring both time to find a contact and the number of errors made (where someone selects the wrong contact). Perhaps moving quickly and tapping the wrong name or other kinds of errors may come up. \n",
    "\n",
    "Subjects will also rate their effort on a 1-7 scale (called a Likert scale). So we get some subjective feedback about how much effort they think each technique take. \n",
    "\n",
    "To put this down, we have 20 subjects. We have 3 techniques, initially 2 then 3 and they are \"Search\", \"Scroll\", and later \"Voice\". \n",
    "\n",
    "And the measures that we want are the time to find the context, the number of errors made, and the effort on a 1-7 scale (Likert Scale). \n",
    "\n",
    "These are getting a little bit more interesting than what we've looked at before. But we're able to take on more complicated analyses because we have a more sophisticated analyses at our disposal. \n",
    "\n",
    "We can ask ourselves with this one factor called technique with 3 levels or 2 level initially. It's a nominal factor or categorical as we've seen before. We have time which is a dependent variable or response variable. Time is a numeric result. We also have errors, which is also numeric. \n",
    "\n",
    "And effort...this would be called ordinal measure because a 1-7 scale (while it's a number) is an ordered scale. The gap conceptually for a person between 2 and 3 may not be how they perceive the gap between 6 and 7 or 5 and 6. Those gaps may be bigger or smaller. They're more of a subject concept. So that's called an ordinal variable where you know there's an order but you don't know the distance between each step in that order. \n",
    "\n",
    "Now...is the technique a within or between subjects variable?\n",
    "\n",
    "Well...we said each of the 20 subjects does all 3 techniques so therefore, it would be a within subjects variable (factor). \n",
    "\n",
    "These are also called repeated measures. \n",
    "\n",
    "And you'll see those terms used interchangeably, it's important to understand they're the same thing. \n",
    "\n",
    "Now..let's ask ourselves, when should we use within subjects variables vs between subjects variables?\n",
    "\n",
    "What would be the considerations there?\n",
    "\n",
    "The short answer is...you should use within subjects variable whenever you can. \n",
    "\n",
    "Why is that? For one thing, it takes many fewer subjects to get the same amount of data. We would need 60 subjects if each subject only did one of the techniques. But we'd need 20 if they each do all three. \n",
    "\n",
    "So we have more data from fewer subjects we have to recruit. \n",
    "\n",
    "It's also preferable because we want to remember that experiments are designed to detect differences. Well, what are the differences that we're looking for here between the 3 different techniques? We want to know in our measures if those 3 techniques perform differently. And when we're trying to detect differences, we're doing that against a backdrop of natural variation, measurement error, and general noise. So anything that reduces the variances in our measurements is a good thing. Leaving to stand out, hopefully, the variance or differences in the things we care about. \n",
    "\n",
    "And so, when we have within subject studies, the variance is less than if we have between subject studies..because you are more like than you are like anyone else. Every subject is more like themselves than they are anyone else. And so, that reduces individual differences and the variance that rises as a result. \n",
    "\n",
    "But there's one very important challenge with within subjects factors, and that is the potential for carry-over effects. That's because each subject does all three. \n",
    "\n",
    "We have to be careful that the order that they do them in is not causing them to perform differently than they would if they only did one each, and we had a between subject study. We have to be careful that we're not introducing a form of confounds. \n",
    "\n",
    "We've talked about confounds before. Now, carryover effects are a major source of confounds and within subjects' studies because the order we present things in can confound the result. \n",
    "\n",
    "So what are the kinds of carryover effects that arise in within subject studies? Examples are fatigue, practice effects, boredom, or skill transfer, where being in search made you better at scrolling or being in scrolling made you better at voice and we presented them in a certain order. Then we might be in fact differentially affecting future conditions based on prior ones, those are skill transfer effects. \n",
    "\n",
    "How would we test for an order effect? Turns out we can know if they're happening. But we have to encode another variable in our dataset. And that variable would be the presentation order of the conditions. So we have technique as a variable but we'd also add to our set the variable order or maybe technique order. \n",
    "\n",
    "And we'd encode that with just say one, two, or in a case of voice being added, three for which order was the measure taken in. And then we simply do a test like we would on technique to know the difference between the techniques. We do a test on order 1, 2, or 3 to see if there's a difference and the result just based on the order that things were shown in. And I obviously hope there is not such a difference. That would mean we don't have an order effect. So we want to think ahead to make sure we log that as part of our data. \n",
    "\n",
    "It still elaves open the question though. How are these orders assigned? How are orders one, two, and three actually put together? And for that, we want to go to our counterbalancing schemes. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterbalancing repeated measures factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've just been discussing the schemes for how we would assign the presentation order of techniques in our study to avoid carryover effects that introduce confounds to our results. The study we're considering again is a within-subjects design where subjects use 3 different techniques to find contacts in a smart phone contacts manager, and we measure the time it takes, the errors they make, and the effort rating that they give each ofo those techniques. So let's talk about how we assigned order of presentation more generally and how that helps us avoid confounds due to carryover effects. There are 3 strategies that we'll consider. \n",
    "\n",
    "We're going to look at full counterbalancing, latin squares, and balanced latin square. \n",
    "\n",
    "Let's start with full counterbalancing. \n",
    "\n",
    "Full counterbalancing is where every possible ordering of conditions is expressed in your study. And it is, when you can do it, the best way to counterbalance the presentation order of your factors. So with full counterbalancing, we have every order expressed. Let's say we have 2 levels of a within-subjects factor. So 2 conditions, let's call them A and B. Full counterbalancing would present A and then B, and then B and then A to the subjects. Because we have 2 sequences, we could say half the subjects or every other subject coming, first would see A then would see B. The other half would see B and then A. So with 2 levels, we need 2 factorial sequences or just 2 sequences. You can see with this factorial operator things are going to grow quickly. With 3 conditions, we'd need A, B, and C. We'd need A/C/B, B/C/A, C/A/B, and C/B/A. Whoa...that went big fast! We now have 6. With 3, we have 6 sequences that need to be expressed. We'd need a study that had subjects that are multiples of 6 in number so 6 subjects or 12 or 18 or 24 subjects, to make sure we have a balanced expression across all 6 sequences. With 4 conditions, I won't even draw them but we'd need 24 sequences. With 5, we'd need 120 sequences (5 factorial = 120). And with 6, it gets unweildy. That's full counterbalancing, expressing every order of conditions that can happen. \n",
    "\n",
    "And we'd need a lot of subjects to make sure we cover all of those orders. So if you can do full counterbalancing, that's the best thing to do. \n",
    "\n",
    "Let's consider something called Latin Squares. \n",
    "\n",
    "Latin Squares just need n sequences for n conditions and therefore, multiples of n subjects. So that sounds nice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
