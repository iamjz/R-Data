{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introduction\n",
    "\n",
    "So we've just looked at generalized linear models or GLMs as generalizations of linear models which are typical anovas..but to respsones that are not normal and that allow us to handle repsonse distributions like poisson or multinomial or ordinal responses. \n",
    "\n",
    "As we've said, the linear model generalizes to the generalized linear model. But this generalized linear model can only handle between-subject's data. Now we're going to introduce what are called mixed models. And there is a linear mixed model. We'll look at its generalization, the generalized linear mixed model. \n",
    "\n",
    "And both of these analyses can handle both between and within subjects data, allowing us to handle data with repeated measures, which in interaction design and HCI studies, repeated measures come up all the time. So these are very powerful models. \n",
    "\n",
    "Let's set our scenario and then we'll describe more what it means to be a mixed model. Our scenario is that we'll return to our data for our mobile text entry study, where we had people using 2 different keyboards in 3 different postures (sitting, standing, and walking). You might recall we had 24 subjects, they were in 2 conditions of keyboard (iphone and galaxy). \n",
    "\n",
    "They were in 3 postures (sit, stand, and walk). Keyboard was between subjects and postures was within subjects. \n",
    "\n",
    "And they entered 20 phases, which we might call a trial which is a general term meaning a sort of a single data point that we're going to capture from a subject. \n",
    "\n",
    "Before we averaged their words per minute and their error rate. But now, we're going to keep all 20 phrases and thus brings us to 1440 data points for this datatable that we can analyze. So we're keeping all of the individual phrases that we measure, and not averaging over them anymore. \n",
    "\n",
    "So that's our scenario and we'll return to analyze that data shortly. But to do that, we're going to have to introduce the concept of random effects and what we've been working with all along but havent' called them this yet are fixed effects. When you have both of this in a statistical model, you have the mixed term for mixed model which is their generalized linear mixed model and linear mixed model or mixing fixed and random effects. So what are these? \n",
    "\n",
    "Fixed effects are the factors of interest that we manipulate in a study. There have been the kinds of variables, the independent variables, we've looked at all along. Keyboard and posture are fixed effects. They're the factors in our study. Random effects - we haven't considered yet. \n",
    "\n",
    "Random effects have a very special meaning and allow us to use linear mixed in general as linear mixed models. \n",
    "\n",
    "Random effects are factors whose levels were sampled randomly from a larger population about which we wish to generalize but whose specific level values we actually don't care about. \n",
    "\n",
    "So in interaction design and HCI studies, subjec is a classic random effect. The subjects are sampled from a population of subjects we wish to generalize about and we don't care about the specific levels of the subject factor. They're coded 1, 2, 3, and so son for however many subjects we may have. Actually, we had 24 subjects in this particular study so we'll go with 24. But we don't care about the specific levels. We just care that we have a pool of subjects. They are a classic random effect and by makign them a random effect in our models with otherwise fixed effects, we have linear mixed models and if we need them, generalized linear mixed models for different kinds of responses. \n",
    "\n",
    "Subject included in the model allows us to correlate measures across the same subjects, across different rows in our data table. And that's how we can handle within subject's design using mixed models. \n",
    "\n",
    "Mixed models have a number of advantages and they're very powerful indeed. They can have some missing data cells. If you drop data, you can still use a mixed model approach to analyze that data and it doesn't thwart your study to have some empty cells in your data table. You can also better handle unbalanced designs where you have different amounts of data in different conditions. There's also no long a Mauchly's sphericity test needed anymore. We don't worry about the sphericity property. We just model the covariance in the data directly. \n",
    "\n",
    "Remember that sphericity is the situation where variances of the differences between all combinations of levels of a within subject factor are equal or close to equal. Now, we care about that but we can model sphericity however form it takes. Whatever form it takes directly. \n",
    "\n",
    "What are the disadvantages of using mixed models? I just cited 3 advantaes but what are the disadvantages? Well, they're just computationally move intensive. Sometimes, they can take longer to run. They also return larger denominator degrees of freedom, what we've seen as the DF residuals or DF denominator. \n",
    "\n",
    "Now to do this kind of analysis where we have each of our 20 trials, there's one more item that we have to consider and this comes up a lot with mixed models and that is the idea of nesting. In particular, the idea of nested effects. And it's a practical matter to consider when using mixed models. \n",
    "\n",
    "So what's a nested effect?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
